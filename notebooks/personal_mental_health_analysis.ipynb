{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5ca599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_analysis_output(content, mode='a'):\n",
    "    \"\"\"Save analysis output to a file in the output directory.\"\"\"\n",
    "    output_file = '../output/analysis_results.txt'\n",
    "    with open(output_file, mode, encoding='utf-8') as f:\n",
    "        f.write(content + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155d60c",
   "metadata": {},
   "source": [
    "# Digital Emotional Footprints: A Data-Driven Analysis of Women's Mental Health Expression\n",
    "\n",
    "This notebook analyzes digital expressions of women's mental health through personal messages and social media to understand emotional patterns and support networks. We'll analyze:\n",
    "- Digital expression patterns across platforms\n",
    "- Temporal emotional signatures\n",
    "- Support-seeking behaviors\n",
    "- Location-based emotional wellbeing\n",
    "- Platform-specific expression trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b13fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('../output', exist_ok=True)\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_theme()\n",
    "\n",
    "# Load both data sources\n",
    "personal_df = pd.read_csv('../data/personal_messages_sample.csv')\n",
    "social_df = pd.read_csv('../data/social_media_posts.csv')\n",
    "\n",
    "# Add source column to each dataset\n",
    "personal_df['source'] = 'Personal Message'\n",
    "social_df['source'] = 'Social Media'\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "personal_df['timestamp'] = pd.to_datetime(personal_df['timestamp'])\n",
    "social_df['timestamp'] = pd.to_datetime(social_df['timestamp'])\n",
    "\n",
    "# Combine datasets with common columns\n",
    "common_columns = ['timestamp', 'message', 'mood_logged', 'source', 'location']\n",
    "df = pd.concat([\n",
    "    personal_df[common_columns],\n",
    "    social_df.assign(message=social_df['message'])[common_columns]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Add time-based features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "# Save dataset overview\n",
    "overview = f\"\"\"Dataset Overview\n",
    "-----------------\n",
    "Time period: {df['timestamp'].min()} to {df['timestamp'].max()}\n",
    "Total messages: {len(df)}\n",
    "\n",
    "Messages by source:\n",
    "{df['source'].value_counts().to_string()}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if 'platform' in social_df.columns:\n",
    "    overview += f\"\\nSocial Media Platforms Used:\\n{social_df['platform'].value_counts().to_string()}\\n\"\n",
    "\n",
    "overview += f\"\\nLocations:\\n{df['location'].value_counts().to_string()}\"\n",
    "overview += f\"\\n\\nUnique moods/emotions:\\n{df['mood_logged'].value_counts().to_string()}\"\n",
    "\n",
    "save_analysis_output(overview, mode='w')  # 'w' mode to start fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e528393",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "This analysis combines two data sources:\n",
    "1. Personal Messages: Direct messages and personal communications\n",
    "2. Social Media Tweets: Public posts related to women's mental health\n",
    "\n",
    "By analyzing both personal and public communications, we can get a more comprehensive view of emotional patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd13892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map moods to five universal emotions\n",
    "def categorize_universal_emotion(mood):\n",
    "    # Mapping of moods to universal emotions (expanded to catch more variations)\n",
    "    emotion_mapping = {\n",
    "        'Joy': ['happy', 'excited', 'ecstatic', 'peaceful', 'accomplished', 'grateful', \n",
    "                'energized', 'content', 'determined', 'loving', 'positive', 'pleased',\n",
    "                'satisfied', 'cheerful', 'optimistic', 'hopeful'],\n",
    "        'Sadness': ['sad', 'down', 'exhausted', 'guilty', 'overwhelmed', 'negative',\n",
    "                    'depressed', 'lonely', 'hopeless', 'disappointed', 'heartbroken'],\n",
    "        'Fear': ['anxious', 'worried', 'stressed', 'unwell', 'nervous', 'scared',\n",
    "                 'insecure', 'uncertain', 'panicked', 'afraid', 'terrified'],\n",
    "        'Anger': ['frustrated', 'conflicted', 'angry', 'irritated', 'annoyed',\n",
    "                  'furious', 'outraged', 'mad', 'resentful', 'hostile'],\n",
    "        'Disgust': ['disgusted', 'hate', 'repulsed', 'revolted', 'dislike',\n",
    "                    'aversion', 'distaste', 'loathing', 'disapproval']\n",
    "    }\n",
    "    \n",
    "    # Convert mood to lowercase for matching\n",
    "    mood_lower = str(mood).lower()\n",
    "    \n",
    "    # Find which universal emotion contains this mood\n",
    "    for emotion, moods in emotion_mapping.items():\n",
    "        if any(m in mood_lower for m in moods):\n",
    "            return emotion\n",
    "    \n",
    "    # If no clear match, try to infer from context or keywords\n",
    "    if any(word in mood_lower for word in ['good', 'great', 'wonderful', 'awesome']):\n",
    "        return 'Joy'\n",
    "    elif any(word in mood_lower for word in ['bad', 'terrible', 'miserable']):\n",
    "        return 'Sadness'\n",
    "    elif any(word in mood_lower for word in ['concerned', 'uneasy']):\n",
    "        return 'Fear'\n",
    "    elif any(word in mood_lower for word in ['upset', 'agitated']):\n",
    "        return 'Anger'\n",
    "    elif any(word in mood_lower for word in ['awful', 'gross']):\n",
    "        return 'Disgust'\n",
    "    \n",
    "    return 'Joy'  # Default to Joy for ambiguous positive expressions\n",
    "\n",
    "# Add universal emotion category to the dataframe\n",
    "df['universal_emotion'] = df['mood_logged'].apply(categorize_universal_emotion)\n",
    "\n",
    "# Save the emotion distribution analysis\n",
    "emotion_distribution = \"Distribution of Universal Emotions:\\n\" + \"-\" * 30\n",
    "emotion_by_source = pd.crosstab(df['source'], df['universal_emotion'], normalize='index') * 100\n",
    "\n",
    "# Save percentages for each source\n",
    "for source in emotion_by_source.index:\n",
    "    emotion_distribution += f\"\\n\\n{source}:\"\n",
    "    for emotion in emotion_by_source.columns:\n",
    "        percentage = emotion_by_source.loc[source, emotion]\n",
    "        emotion_distribution += f\"\\n{emotion}: {percentage:.1f}%\"\n",
    "\n",
    "save_analysis_output(emotion_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19095ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define consistent colors and order for universal emotions\n",
    "UNIVERSAL_EMOTIONS = ['Joy', 'Sadness', 'Fear', 'Anger', 'Disgust']\n",
    "EMOTION_COLORS = {\n",
    "    'Joy': '#FFD700',      # Gold\n",
    "    'Sadness': '#4169E1',  # Royal Blue\n",
    "    'Fear': '#32CD32',     # Lime Green\n",
    "    'Anger': '#DC143C',    # Crimson\n",
    "    'Disgust': '#800080'   # Purple\n",
    "}\n",
    "\n",
    "# Create visualization for universal emotions throughout the day\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create emotion distribution by hour with all emotions\n",
    "emotion_by_hour = pd.crosstab(df['hour'], df['universal_emotion'])\n",
    "\n",
    "# Add missing emotions with zero counts\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion not in emotion_by_hour.columns:\n",
    "        emotion_by_hour[emotion] = 0\n",
    "\n",
    "# Ensure consistent emotion order\n",
    "emotion_by_hour = emotion_by_hour[UNIVERSAL_EMOTIONS]\n",
    "\n",
    "# Plot with specific colors\n",
    "emotion_by_hour.plot(kind='bar', stacked=True, \n",
    "                    color=[EMOTION_COLORS[emotion] for emotion in UNIVERSAL_EMOTIONS])\n",
    "plt.title('Universal Emotions Throughout the Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.legend(title='Emotion', bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the daily emotions plot\n",
    "plt.savefig('../output/daily_emotions_distribution.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create pie chart of overall emotion distribution\n",
    "plt.figure(figsize=(10, 8))\n",
    "emotion_counts = df['universal_emotion'].value_counts()\n",
    "\n",
    "# Add missing emotions with zero counts\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion not in emotion_counts.index:\n",
    "        emotion_counts[emotion] = 0\n",
    "\n",
    "# Ensure consistent emotion order\n",
    "emotion_counts = emotion_counts[UNIVERSAL_EMOTIONS]\n",
    "\n",
    "# Plot pie chart\n",
    "plt.pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%',\n",
    "        colors=[EMOTION_COLORS[emotion] for emotion in UNIVERSAL_EMOTIONS],\n",
    "        startangle=90)\n",
    "plt.title('Distribution of Universal Emotions')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Emotions\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "plt.axis('equal')\n",
    "\n",
    "# Save the emotion distribution pie chart\n",
    "plt.savefig('../output/emotion_distribution_pie.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save peak times information to the text file\n",
    "peak_times_text = \"\\nPeak Times for Universal Emotions:\\n\" + \"-\" * 30 + \"\\n\"\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion in emotion_by_hour.columns and emotion_by_hour[emotion].max() > 0:\n",
    "        peak_hour = emotion_by_hour[emotion].idxmax()\n",
    "        count = emotion_by_hour[emotion][peak_hour]\n",
    "        peak_times_text += f\"{emotion}: {peak_hour}:00 hours ({count} messages)\\n\"\n",
    "    else:\n",
    "        peak_times_text += f\"{emotion}: No occurrences found\\n\"\n",
    "\n",
    "save_analysis_output(peak_times_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed19d09",
   "metadata": {},
   "source": [
    "## Social Media Platform Analysis\n",
    "\n",
    "Let's analyze how emotions vary across different social media platforms and compare them with personal messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad60a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze emotions across platforms\n",
    "social_df['universal_emotion'] = social_df['mood_logged'].apply(categorize_universal_emotion)\n",
    "\n",
    "# Create a comparison plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Calculate emotion distribution for each platform\n",
    "platform_emotions = pd.crosstab(social_df['platform'], social_df['universal_emotion'], normalize=False)\n",
    "\n",
    "# Add missing emotions with zero counts\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion not in platform_emotions.columns:\n",
    "        platform_emotions[emotion] = 0\n",
    "\n",
    "# Ensure consistent emotion order and calculate percentages\n",
    "platform_emotions = platform_emotions[UNIVERSAL_EMOTIONS]\n",
    "platform_emotions = (platform_emotions.div(platform_emotions.sum(axis=1), axis=0) * 100)\n",
    "\n",
    "# Plot\n",
    "platform_emotions.plot(kind='bar', stacked=True, \n",
    "                     color=[EMOTION_COLORS[emotion] for emotion in UNIVERSAL_EMOTIONS])\n",
    "plt.title('Emotional Expression Across Social Media Platforms')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Percentage of Posts')\n",
    "plt.legend(title='Emotion', bbox_to_anchor=(1.05, 1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the platform analysis plot\n",
    "plt.savefig('../output/platform_emotion_analysis.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save platform-specific insights to text file\n",
    "platform_insights = \"\\nEmotional Expression by Platform:\\n\" + \"-\" * 30\n",
    "for platform in social_df['platform'].unique():\n",
    "    platform_data = social_df[social_df['platform'] == platform]\n",
    "    platform_insights += f\"\\n\\n{platform}:\\n\"\n",
    "    platform_insights += f\"Total posts: {len(platform_data)}\\n\"\n",
    "    emotion_counts = platform_data['universal_emotion'].value_counts()\n",
    "    total_posts = len(platform_data)\n",
    "    for emotion in UNIVERSAL_EMOTIONS:\n",
    "        count = emotion_counts.get(emotion, 0)\n",
    "        percentage = (count / total_posts) * 100 if total_posts > 0 else 0\n",
    "        platform_insights += f\"  {emotion}: {percentage:.1f}%\\n\"\n",
    "\n",
    "save_analysis_output(platform_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebee604",
   "metadata": {},
   "source": [
    "## Universal Emotions Daily Patterns Analysis\n",
    "\n",
    "Let's analyze how the five universal emotions (Joy, Sadness, Fear, Anger, and Disgust) vary throughout the day and week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "096bf735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract hour and day from timestamp\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "\n",
    "# Create distribution by hour for universal emotions\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_emotion_patterns = pd.crosstab(df['hour'], df['universal_emotion'])\n",
    "\n",
    "# Add missing emotions with zero counts\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion not in daily_emotion_patterns.columns:\n",
    "        daily_emotion_patterns[emotion] = 0\n",
    "\n",
    "# Ensure consistent emotion order\n",
    "daily_emotion_patterns = daily_emotion_patterns[UNIVERSAL_EMOTIONS]\n",
    "\n",
    "# Plot with consistent colors\n",
    "daily_emotion_patterns.plot(kind='bar', stacked=True,\n",
    "                          color=[EMOTION_COLORS[emotion] for emotion in UNIVERSAL_EMOTIONS])\n",
    "plt.title('Universal Emotions Distribution Throughout the Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.legend(title='Universal Emotions', bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the daily emotion patterns plot\n",
    "plt.savefig('../output/daily_emotion_patterns.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save hourly analysis information\n",
    "hourly_analysis = \"\\nUniversal Emotions by Hour:\\n\" + \"-\" * 30 + \"\\n\"\n",
    "\n",
    "# Peak times for each universal emotion\n",
    "hourly_analysis += \"\\nPeak Hours for Each Universal Emotion:\\n\"\n",
    "for emotion in UNIVERSAL_EMOTIONS:\n",
    "    if emotion in daily_emotion_patterns.columns and daily_emotion_patterns[emotion].max() > 0:\n",
    "        peak_hour = daily_emotion_patterns[emotion].idxmax()\n",
    "        count = daily_emotion_patterns[emotion][peak_hour]\n",
    "        hourly_analysis += f\"{emotion}: {peak_hour:02d}:00 hours ({count} messages)\\n\"\n",
    "    else:\n",
    "        hourly_analysis += f\"{emotion}: No occurrences found\\n\"\n",
    "\n",
    "# Emotional balance for key times of day\n",
    "morning_hours = daily_emotion_patterns.loc[6:11].sum()\n",
    "afternoon_hours = daily_emotion_patterns.loc[12:17].sum()\n",
    "evening_hours = daily_emotion_patterns.loc[18:23].sum()\n",
    "\n",
    "hourly_analysis += \"\\nEmotional Balance by Time of Day:\\n\"\n",
    "\n",
    "def format_timeblock_analysis(timeblock_name, data):\n",
    "    total = data.sum()\n",
    "    analysis = f\"\\n{timeblock_name}:\\n\"\n",
    "    for emotion in UNIVERSAL_EMOTIONS:\n",
    "        count = data.get(emotion, 0)\n",
    "        percentage = (count / total * 100) if total > 0 else 0\n",
    "        analysis += f\"  {emotion}: {percentage:.1f}%\\n\"\n",
    "    return analysis\n",
    "\n",
    "hourly_analysis += format_timeblock_analysis(\"Morning (6:00-11:59)\", morning_hours)\n",
    "hourly_analysis += format_timeblock_analysis(\"Afternoon (12:00-17:59)\", afternoon_hours)\n",
    "hourly_analysis += format_timeblock_analysis(\"Evening (18:00-23:59)\", evening_hours)\n",
    "\n",
    "save_analysis_output(hourly_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8377635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create emotion distribution by day of week\n",
    "plt.figure(figsize=(12, 6))\n",
    "emotion_by_day = pd.crosstab(df['day_of_week'], df['universal_emotion'])\n",
    "\n",
    "# Reorder days of week\n",
    "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "emotion_by_day = emotion_by_day.reindex(days_order)\n",
    "\n",
    "# Define colors for each universal emotion\n",
    "emotion_colors = {\n",
    "    'Joy': '#FFD700',      # Gold\n",
    "    'Sadness': '#4169E1',  # Royal Blue\n",
    "    'Fear': '#32CD32',     # Lime Green\n",
    "    'Anger': '#DC143C',    # Crimson\n",
    "    'Disgust': '#800080'   # Purple\n",
    "}\n",
    "\n",
    "# Plot with specific colors\n",
    "emotion_by_day.plot(kind='bar', stacked=True,\n",
    "                   color=[emotion_colors.get(emotion, '#808080') for emotion in emotion_by_day.columns])\n",
    "plt.title('Universal Emotions Across Week Days')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.legend(title='Emotion', bbox_to_anchor=(1.05, 1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the weekly emotion patterns plot\n",
    "plt.savefig('../output/weekly_emotion_patterns.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save weekly analysis text\n",
    "weekly_analysis = \"\\nWeekly Emotional Analysis\\n\" + \"=\" * 25 + \"\\n\"\n",
    "\n",
    "# Add dominant emotion by day\n",
    "weekly_analysis += \"\\nDominant Emotion by Day:\\n\" + \"-\" * 30 + \"\\n\"\n",
    "for day in days_order:\n",
    "    if day in emotion_by_day.index:\n",
    "        dominant_emotion = emotion_by_day.loc[day].idxmax()\n",
    "        count = emotion_by_day.loc[day][dominant_emotion]\n",
    "        total = emotion_by_day.loc[day].sum()\n",
    "        percentage = (count / total) * 100\n",
    "        weekly_analysis += f\"{day}: {dominant_emotion} ({percentage:.1f}% of messages)\\n\"\n",
    "\n",
    "# Add emotional balance by day\n",
    "weekly_analysis += \"\\nEmotional Balance by Day:\\n\" + \"-\" * 30\n",
    "for day in days_order:\n",
    "    if day in emotion_by_day.index:\n",
    "        day_total = emotion_by_day.loc[day].sum()\n",
    "        weekly_analysis += f\"\\n\\n{day}:\"\n",
    "        for emotion in emotion_by_day.columns:\n",
    "            if emotion != 'Other':\n",
    "                count = emotion_by_day.loc[day].get(emotion, 0)\n",
    "                percentage = (count / day_total) * 100\n",
    "                weekly_analysis += f\"\\n  {emotion}: {percentage:.1f}%\"\n",
    "\n",
    "save_analysis_output(weekly_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a7542b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Personal Wellness Analysis...\n",
      "\n",
      "Analysis complete! Results have been saved to the output directory.\n",
      "Analysis complete! Results have been saved to the output directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Generating Personal Wellness Analysis...\\n\")\n",
    "\n",
    "# Add personal context columns\n",
    "df['time_of_day'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "df['is_weekend'] = pd.to_datetime(df['timestamp']).dt.dayofweek >= 5\n",
    "\n",
    "# Group emotions by context\n",
    "location_emotions = df.groupby(['location', 'universal_emotion']).size().unstack(fill_value=0)\n",
    "time_emotions = df.groupby(['time_of_day', 'universal_emotion']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure all emotions are present in each analysis\n",
    "for emotions_df in [location_emotions, time_emotions]:\n",
    "    for emotion in UNIVERSAL_EMOTIONS:\n",
    "        if emotion not in emotions_df.columns:\n",
    "            emotions_df[emotion] = 0\n",
    "    # Reorder columns to match universal emotions order\n",
    "    emotions_df = emotions_df[UNIVERSAL_EMOTIONS]\n",
    "\n",
    "# Save location-based analysis\n",
    "location_analysis = \"Personal Wellness Analysis\\n\" + \"=\"*25 + \"\\n\\n\"\n",
    "location_analysis += \"Emotional Patterns by Location:\\n\" + \"-\" * 30 + \"\\n\"\n",
    "for location in location_emotions.index:\n",
    "    dominant_emotion = location_emotions.loc[location].idxmax()\n",
    "    location_analysis += f\"{location}: Most common emotion is {dominant_emotion}\\n\"\n",
    "\n",
    "# Visualize and save time-based patterns\n",
    "plt.figure(figsize=(12, 6))\n",
    "time_emotions[UNIVERSAL_EMOTIONS].plot(kind='area', stacked=True,\n",
    "                                    color=[EMOTION_COLORS[emotion] for emotion in UNIVERSAL_EMOTIONS])\n",
    "plt.title('Emotional Patterns Throughout the Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.legend(title='Emotions', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/daily_emotional_flow.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save personalized insights\n",
    "insights = \"\\nPersonalized Insights:\\n\" + \"-\" * 30\n",
    "\n",
    "# Most positive times\n",
    "joy_times = time_emotions['Joy'].nlargest(3)\n",
    "insights += \"\\n\\nBest times for wellbeing:\"\n",
    "for hour, count in joy_times.items():\n",
    "    insights += f\"\\n- {hour:02d}:00 hours\"\n",
    "\n",
    "# Potential trigger times\n",
    "negative_times = time_emotions[['Sadness', 'Fear', 'Anger']].sum(axis=1).nlargest(3)\n",
    "insights += \"\\n\\nTimes to be mindful:\"\n",
    "for hour, _ in negative_times.items():\n",
    "    insights += f\"\\n- {hour:02d}:00 hours\"\n",
    "\n",
    "# Location-based recommendations\n",
    "insights += \"\\n\\nLocation-based insights:\"\n",
    "for location in location_emotions.index:\n",
    "    joy_ratio = location_emotions.loc[location, 'Joy'] / location_emotions.loc[location].sum()\n",
    "    if joy_ratio >= 0.5:\n",
    "        insights += f\"\\n✨ {location} appears to be a positive environment ({joy_ratio*100:.1f}% positive emotions)\"\n",
    "    elif joy_ratio <= 0.3:\n",
    "        insights += f\"\\n⚠️ Consider limiting time at {location} ({(1-joy_ratio)*100:.1f}% negative emotions)\"\n",
    "\n",
    "save_analysis_output(location_analysis)\n",
    "save_analysis_output(insights)\n",
    "\n",
    "print(\"Analysis complete! Results have been saved to the output directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
